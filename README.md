<p align="center">
  <h1 align="center">Facial Manipulation Detection</h1>
</p>

# Introduction

In recent years, the rise of advanced image generation and manipulation techniques, such as Generative Adversarial Networks (GANs) and face-swapping algorithms, has posed significant challenges for distinguishing between real and fake images. This project aims to develop and evaluate a classifier designed to differentiate between authentic facial images and those altered using face-swapping techniques. The project's progression involves initially testing a simple classifier, then advancing to a more complex model to improve classification accuracy.

## Project Overview

This project is structured in two main phases to develop a robust classifier capable of distinguishing between real and fake facial images. The phases are designed to progressively enhance the classifier's accuracy and reliability, particularly when faced with sophisticated image manipulations.

### Phase 1: Simple Classifier Development and Evaluation - SimpleNet

Objective: 
* Create a basic neural network classifier to differentiate between real and face-swapped images.

Approach:
* Implement a straightforward neural network architecture.
* Train the classifier on a dataset containing genuine facial images and fake images generated by the FaceSwap network, which involves transplanting one face onto another.
* Evaluate the performance of the classifier on this initial dataset to establish a baseline understanding of its capabilities.

### Phase 2: Advanced Classifier Development and Evaluation - Xception backbone

Objective: 
* Improve the classifier's performance to effectively distinguish between real and fake images in more complex scenarios.

Approach:
* Develop an advanced classifier based on the Xception backbone, known for its high accuracy in image classification tasks.
* Train and test the advanced classifier on a more challenging dataset, where:
  - Real images are generated by a Progressive GAN (PGAN) model, producing high-quality synthetic facial images.
  - Fake images are the same face-swapped images used in Phase 1.
* Assess the advanced model's ability to accurately identify fake images, demonstrating its improved performance over the simple classifier.

## Expected Outcomes
* Phase 1: The simple classifier is expected to exhibit limitations in accurately distinguishing between real and fake images, underscoring the need for more sophisticated models.
* Phase 2: The advanced classifier with the Xception backbone is anticipated to achieve higher accuracy in identifying fake images, validating the effectiveness of complex models in detecting advanced image manipulations.

# Datasets

<div align="center">
  <img src="figures/datasets_samples.png", width="600">
</div>

There are 2 datasets I used in this project:
* Fakes dataset:
  - Real existing identities images.
  - Fake planted faces into the context of another (faceswap).
* Synthetic dataset:
  - Synthetic images created by PGAN.
  - Fake planted faces into the context of another (faceswap).

# Phase 1 - SimpleNet
## Loss / Accuracy

<div align="center">
  <img src="figures/fakes_dataset_SimpleNet_losses_plot.png", width="400">
  <img src="figures/fakes_dataset_SimpleNet_accuracies_plot.png", width="400">
</div>

* SimpleNet reached 97.7% accuracy on the Train set.
* SimpleNet reached 89.7% accuracy on the Validation set.
* SimpleNet reached 85.7% accuracy on the Test set.

## ROC / DET curves
<div align="center">
  <img src="figures/fakes_dataset_SimpleNet_roc_curve.png", width="400">
  <img src="figures/fakes_dataset_SimpleNet_det_curve.png", width="400">
</div>

### ROC curve
The ROC (Receiver Operating Characteristic) curve is a graphical representation commonly used in binary classification tasks to evaluate the performance of a model. It illustrates the trade-off between the true positive rate (sensitivity) and the false positive rate (1-specificity) at various classification thresholds. The area under the ROC curve called AuC. 
The following image represents the ROC curve corresponding to the classifier performance:

For a random classifier we will get a diagonal line, and for a good classifier we will get a curve that is more like the blue line. For perfect classifier the AuC will be equal 1, and for the worse 0.

We defined the labels for the real images as 0, and for fake images as 1, so when we supplied the first scores to the ROC function with the labels, it reversed the plot. And instead of getting blue like curve for the first score outputs, we got curve that represents low performance classifier. Of course, it isn’t true, and we got it only because the True Positive labels here are 0’s. 
For the second scores we got normal ROC curve that represents a classifier with good performance as expected.
For conclusion, the ROC curve of both scores are good and showing that the classifier performance is high.
The same thing happened with the AuC. The AuC for the first scores is 0.074 but we need to calculate it as 1-0.074=0.926. For the second scores we got 0.925. pretty close values and both are close to 1.

### DET curve
The DET (Detection error tradeoff) curve is similar to the ROC curve but uses a different scale to plot the false positive rate (FPR) against the false negative rate (FNR). The better is the classifier, the closer the curve will be to the bottom-left corner of the plot. This corner represents low false positive rates (FPR) and low false negative rates (FNR), indicating high accuracy and precision.
The same inversion of the first scores curve happened here. The second scores shown as good classifier curve and the first scores shown as bad classifier curve, but it is actually also representing a good classifier curve.

## Complex Manipulation

<div align="center">
  <img src="figures/synthetic_dataset_SimpleNet_losses_plot.png", width="400">
  <img src="figures/synthetic_dataset_SimpleNet_accuracies_plot.png", width="400">
</div>

We supposed to get classifier that can distinguish between real (synthetic) images to manipulated images where the face isn’t related to the context of the background. But the model couldn’t learn, and the train/validation/test accuracy stayed around 0.5 – we got a random classifier.

This result makes sense because the synthetic real images created by GAN model, and the purpose of a GAN model is to fool the discriminator between fake images it creates. The SimpleNet as its name, is a simple model and can’t achieve high performance with this dataset. In Addition, distribution of the synthetic images isn’t good enough and has narrow and shallow properties. moreover, the proportion of images with the synthetic data set is much smaller compared to the fakes data set, and as we know, more data can lead to better performance with ML classifiers.

# Phase 2 - Xception backbone

Xception is trained on the ImageNet dataset, which is a large dataset containing millions of labeled images across thousands of categories. The network is pre-trained on ImageNet for the task of image classification, where it learns to extract hierarchical features from images to discriminate between different objects, animals, and scenes.

The number of parameters of the Xception architecture showing in the paper is 22,855,952.

We added the following layers:
* Fully-Connected 2048x1000 (replaced the last layer in the backbone)
* ReLU
* Fully-Connected 1000x256
* ReLU
* Fully-Connected 256x64
* ReLU
* Fully-Connected 64x2

Added params = (1000*256+256) + (256*64+64) + (64*2+2) = 274,834

## Loss / Accuracy

<div align="center">
  <img src="figures/synthetic_dataset_XceptionBased_losses_plot.png", width="400">
  <img src="figures/synthetic_dataset_XceptionBased_accuracies_plot.png", width="400">
</div>

We can see from the training data that the Xception based model reached impressive results with just 2 epochs. 
* XceptionBased reached 98.2% accuracy on the Train set.
* XceptionBased reached 98.2% accuracy on the Validation set.
* XceptionBased reached 98.8% accuracy on the Test set.

## ROC / DET curves
<div align="center">
  <img src="figures/synthetic_dataset_XceptionBased_roc_curve.png", width="400">
  <img src="figures/synthetic_dataset_XceptionBased_det_curve.png", width="400">
</div>

We got an almost perfect classifier.

# Saliency Maps and Grad-CAM analysis
## Saliency Maps
Image-Specific Class Saliency Visualization technique is a method used in computer vision to highlight regions of an image that contribute the most to a particular class prediction made by a neural network model. This technique aims to provide insights into why a model makes certain predictions and help understand the decision-making process of the model.
Saliency maps highlight the most relevant regions of an image by computing the importance of each pixel based on its influence on the model's prediction.

### Saliency maps of SimpleNet over fakes dataset

<div align="center">
  <img src="figures/fakes_dataset_SimpleNet_saliency_maps_and_images_pairs.png", width="400">
  <img src="figures/fakes_dataset_SimpleNet_mean_saliency_maps.png", width="400">
</div>

From the mean Saliency maps, we can see that the SimpleNet model mostly classifies real and fake images based on eyes, eyebrows, nose and mouth.

### Saliency maps of XceptionBased over Synthetic dataset

<div align="center">
  <img src="figures/synthetic_dataset_XceptionBased_saliency_maps_and_images_pairs.png", width="400">
  <img src="figures/synthetic_dataset_XceptionBased_mean_saliency_maps.png", width="400">
</div>

From the mean Saliency maps, we can see that the XceptionBased model classifies based on the whole face in the image.

## Grad-CAM
Grad-CAM (Gradient-weighted Class Activation Mapping) is a technique used for generating visual explanations of the decisions made by deep neural networks, particularly convolutional neural networks (CNNs), in the context of image classification tasks. Grad-CAM highlights the regions of an input image that contribute the most to a particular class prediction made by the model.

### Grad-CAM of SimpleNet over fakes dataset

<div align="center">
  <img src="figures/fakes_dataset_SimpleNet_Real_Image_grad_cam.png", width="400">
  <img src="figures/fakes_dataset_SimpleNet_Fake_Image_grad_cam.png", width="400">
</div>

From the Grad-CAM of SimpleNet, we see again it classifies based on eyes, nose, mouth, etc.

### Grad-CAM of SimpleNet over fakes dataset

<div align="center">
  <img src="figures/synthetic_dataset_SimpleNet_Real_Image_grad_cam.png", width="400">
  <img src="figures/synthetic_dataset_SimpleNet_Fake_Image_grad_cam.png", width="400">
</div>

There is no heat-map Grad-CAM on these images. As we saw before, the SimpleNet model acts as random classifier on the Synthetic dataset. That means the model struggles to classify and learn meaningful representations about the images. The Grad-CAM may not be able to provide useful insights into the decision-making process, therfore we don't get any heat map.

### Grad-CAM of XceptionBased over synthetic dataset

<div align="center">
  <img src="figures/synthetic_dataset_XceptionBased_Real_Image_grad_cam.png", width="400">
  <img src="figures/synthetic_dataset_XceptionBased_Fake_Image_grad_cam.png", width="400">
</div>

From the Grad-CAM images of XceptionBased model, we see again it classifies based on the whole face of the image, both for real and fake images.

# Bonus - FixEfficientB0
For the bonus model, we were looking for a model that would have high accuracy in the classification task, but at the same time have a minimum of parameters. After looking for a model with these characteristics, we found the FixEfficientB0 [1] model where we used it as backbone for our model.
The FixEfficientB0 model is based on the known family models EfficientNet [2] with applying a method called FixRes [3] we will explain below. EfficientNet is a convolutional neural network architecture and scaling method that uniformly scales all dimensions of depth/width/resolution using a compound coefficient. Unlike conventional practice that arbitrary scales these factors, the EfficientNet scaling method uniformly scales network width, depth, and resolution with a set of fixed scaling coefficients.
The FixRes method addresses the discrepancy between training and testing resolutions in deep learning models. It involves training models with a range of resolutions and incorporating resolution-aware normalization during training. By doing so, the method improves the model's robustness and performance across different input resolutions, ensuring better generalization to real-world scenarios where resolutions may vary.
The archietcture of the model is based on a block called MBConvBlock. The MBConvBlock is a core component in efficient convolutional neural networks like MobileNetV2 and EfficientNet. It employs an inverted residual connection with expansion and depthwise convolution to reduce computational cost while maintaining high performance.

## Loss / Accuracy

<div align="center">
  <img src="figures/fakes_dataset_bonus_losses_plot.png", width="400">
  <img src="figures/fakes_dataset_bonus_accuracies_plot.png", width="400">
</div>

## ROC / DET curves

<div align="center">
  <img src="figures/fakes_dataset_bonus_roc_curve.png", width="400">
  <img src="figures/fakes_dataset_bonus_det_curve.png", width="400">
</div>

## Saliency maps

<div align="center">
  <img src="figures/fakes_dataset_bonus_saliency_maps_and_images_pairs.png", width="400">
  <img src="figures/fakes_dataset_bonus_mean_saliency_maps.png", width="400">
</div>

## Grad-CAM

<div align="center">
  <img src="figures/fakes_dataset_bonus_Real_Image_grad_cam.png", width="400">
  <img src="figures/fakes_dataset_bonus_Fake_Image_grad_cam.png", width="400">
</div>

# Results

The bonus model reached high performance with low number of parameters.
* The bonus model test accuracy: 93.28%
* The bonus model number of parameters: 5,732,546
